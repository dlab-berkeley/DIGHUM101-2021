{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from datetime import datetime\n",
    "\n",
    "# Don't unhashtag this - yet! \n",
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast review\n",
    "\n",
    "1. What is a list?\n",
    "2. What is a dictionary? \n",
    "3. What is a Pytyon library? \n",
    "4. What are two conventions for importing data from files in Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning objectives\n",
    "\n",
    "0. Review .csv importation, the working directory, and two common errors: Name and File\n",
    "1. Begin to work with data frames in Python (tabular structures, like a spreadsheet!) \n",
    "2. Basic methods: `.head()`, `.rename()`, `.describe()`, and `.value_counts()`\n",
    "3. Basic attributes: `.columns` and `.shape`\n",
    "4. Subsetting: `.iloc()`, `.loc()`, and conditional \n",
    "5. Adding and removing columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "Pandas is designed to make it easier to work with [structured data](https://learn.g2.com/structured-vs-unstructured-data). Most of the analyses you might perform will likely involve using tabular data, e.g., from .csv files or relational databases (e.g., SQL). The DataFrame object in pandas is \"a two-dimensional tabular, column-oriented data structure with both row and column labels.\"\n",
    "\n",
    "**i.e., a spreadsheet!**\n",
    "\n",
    "The pandas name itself is derived from panel data, an econometrics term for multidimensional structured data sets, and Python data analysis itself. [Check out the Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/) to learn more! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import .csv file\n",
    "\n",
    "Import the correspondence dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uh-oh! # What is a NameError? Review \"1-8_errors-help.ipynb\" for a hint.\n",
    "letters = pd.read_csv(\"correspondence-data-1585.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! Now we are good to go, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is a FileError? Review \"1-8_errors-help.ipynb\" for a hint.\n",
    "letters = pd.read_csv(\"correspondence-data-1585.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the working directory\n",
    "\n",
    "Remember to...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, view the file path to your current working directory:\n",
    "# %pwd\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then change the working directory path to the Data folder\n",
    "# Go \"up\" two levels in your file structure and into the Data folder:\n",
    "os.chdir(\"../../Data/\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the files in the working directory\n",
    "# You should see \"correspondence-data-1585.csv\"\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can load the file! :) \n",
    "letters = pd.read_csv(\"correspondence-data-1585.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `.head()`, `.describe()`, and `.value_counts()`\n",
    "\n",
    "The `.head()` method will show the first five rows by default. Put an integer in the parentheses to specify a different number of rows. \n",
    "\n",
    "`.describe()` provides basic summary statistics. \n",
    "\n",
    "`.value_counts()` counts frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first 3 rows\n",
    "letters.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce some quick summary statistics\n",
    "letters.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `.value_counts()`\n",
    "\n",
    "Now, we can investigate how many of each category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many letters by each writer?\n",
    "letters[\"writer\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which city was the most frequent source?\n",
    "letters[\"source\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which city was the most frequent destination?\n",
    "letters[\"destination\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column names\n",
    "\n",
    "You can call [attributes](https://medium.com/@shawnnkoski/pandas-attributes-867a169e6d9b) of a Pandas variable by using \"dot notation\" - but without the parentheses to unpack more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error! No such method exists\n",
    "letters.columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the column names using the .columns *attribute*\n",
    "letters.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Columns\n",
    "\n",
    "Select a single column by typing its name as a string in square brackets. View just the first five rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters[\"writer\"][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double lists\n",
    "\n",
    "You can also call multiple columns by passing their names in as strings to a [double list](https://stackoverflow.com/questions/33417991/pandas-why-are-double-brackets-needed-to-select-column-after-boolean-indexing)! View just the first five rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That's a lot of square brackets!\n",
    "letters[[\"writer\", \"date\"]][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `.rename()`\n",
    "\n",
    "Nice! Now that we know how to access the column names, we can edit the columns names with the .`rename()` method.\n",
    "\n",
    "Pass in a dictionary argument to the columns parameter like this: `columns = {\"old_name\":\"new_name\"}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters.rename(columns = {\"writer\" : \"Writer\", \n",
    "                          \"source\" : \"Origin\",\n",
    "                          \"destination\" : \"Dest\",\n",
    "                          \"date\" : \"Date\"}, \n",
    "               inplace = True) # what does inplace = True mean? How do you find out?\n",
    "\n",
    "# View the updated column names\n",
    "print(letters.columns)\n",
    "\n",
    "# or\n",
    "\n",
    "letters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slice Rows\n",
    "\n",
    "You can slice rows like you would a string or a list. If we just want the 7th, 8th, and 9th rows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters[6:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `.iloc()`\n",
    "\n",
    "... or use `.iloc()` to return non-consecutive rows. Pass in **integers** as a double list. \n",
    "\n",
    "For example, to get the 4th, 12th, and 29th rows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters.iloc[[3, 11, 28]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and pass in a second interior list to specify columns! Select just the \"Writer\" (0th index) and \"Date\" (3rd index) columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters.iloc[[3, 11, 28], [0, 3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `.loc()` \n",
    "\n",
    "While `.iloc()` requires integers, regular `.loc()` allows you to pass in column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters.loc[[3, 11, 28], [\"Writer\", \"Date\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Subsetting\n",
    "\n",
    "What is we want a subset based on a condition? For example, what if we just wanted a subset for data only when Destination is equal to Haarlem? \n",
    "\n",
    "... _and_ Writer is equal to Meulen, Andries van der?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data frame just of Haarlem destinations...\n",
    "h = letters.loc[letters[\"Dest\"] == \"Haarlem\"]\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data frame just of Andries van der Meulen\n",
    "am = letters.loc[letters[\"Writer\"] == \"Meulen, Andries van der\"]\n",
    "am.head()\n",
    "\n",
    "# What does the .shape attribute do?\n",
    "# 63 rows and 4 columns\n",
    "am.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data frame that includes both Haarlem as the destination AND Andries van der Meulen \n",
    "both = letters.loc[(letters[\"Dest\"] == \"Haarlem\") & \n",
    "                   (letters[\"Writer\"] == \"Meulen, Andries van der\")]\n",
    "both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn more by [reading the documentation here](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html) - what is the difference between `&` and `|` ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Column: \n",
    "\n",
    "You can add a new column by renaming it in place - just like with a list or dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters[\"Estimated_Arrival\"] = \"Arrival date\"\n",
    "\n",
    "# All entries for \"Estimated_Arrival\" say \"Arrival date\"\n",
    "letters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can populate this column with the results of some expression/calculation. Perhaps we estimated it would have taken 10 days for a letter to reach its destination.\n",
    "\n",
    "> NOTE: Working with datetimes in Python can be particularly frustrating! You will learn more about custom functions, for loops, list comprehensions, and lambda functions starting in week 3. The reason we are glossing over them now is so that you focus on what is possible for planning your individual projects instead of getting lost and frustrated in the nuances of the Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda function:\n",
    "# letters[\"Date\"] = letters['Date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "\n",
    "# List comprehension\n",
    "letters[\"Date\"] = [datetime.strptime(x, '%Y-%m-%d').date() for x in letters[\"Date\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 10 days to each Date\n",
    "letters['Estimated_Arrival'] = letters['Date'] + pd.DateOffset(days = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "letters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete Column\n",
    "\n",
    "We can use our `del` statement to delete a column just like we did with lists: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Date\" is removed!\n",
    "del letters[\"Date\"]\n",
    "letters.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
