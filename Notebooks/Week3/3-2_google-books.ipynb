{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting Data from the Web - APIs\n",
    "\n",
    "We're going to first explore a simple web API - the Google Books API - to perform some searches for books and see what metadata we get in return. Although many APIs require a key in order to access the data, we can perform Google Books searches without one. The guide to the Google Books API, as well as a lot of other useful information, can be found [here](https://developers.google.com/books/).\n",
    "\n",
    "If you are interested in Reddit and Twitter data check out notebook 3-2_praw-tweepy.ipynb. You can also download Tweets from the Internet by Google searching \"download tweets\". \n",
    "\n",
    "First we'll import the [`requests`](http://docs.python-requests.org/en/master/) library. The `requests` library is necessary for most interaction with the internet in Python. We'll use it to make a `get` request to the API endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install requests  \n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To call an API it to just build a unique URL. We always need a base URL, or endpoint, to which we can add the parameters specific to our request. Let's assign the base Google Books endpoint to a variable, we'll call it `books_url`. We know this URL from the documentation linked above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_url = 'https://www.googleapis.com/books/v1/volumes?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start off with a very simple search to see what the results look like. Then we'll move on to adding more filters and parameters. Let's assign our query to a variable `query`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'digital humanities'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To incorporate this into our query we can make a dictionary called `parameters`. We'll pass these parameters to the `get` method. The `'q'` stands for 'query', and whatever value we assign to that is what we're searching for, just as if we typed it into the Google search bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'q': query}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll pass two arguments to the `get` method of `requests` library: the URL and the parameters we want. It returns a response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(books_url, params = parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the `url` property, we can see that this function converted the URL into the proper format to include our search terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see our results, we simply use the request object's `json` method, which we can then navigate as a Python dictionary. Take a minute or two to navigate through the results in order to see what's there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = r.json()\n",
    "results\n",
    "print(type(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You probably figured out that the books are found under the `'items'` key, and the most important information for each one is under the `'volumeInfo'` key. Let's take a look at the first result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['items'][0]['volumeInfo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot of information in the results, but we probably don't want all of it. Suppose that for each volume in the results, we only want to extract 1) the title, 2) the author(s), 3) the publication date, and 4) the description. Below is a function named `parse_results` that takes the `results` variable as an argument and returns a list of dictionaries. Each dictionary within the list corresponds to a book, and has an `author` key, a `title` key, a `publication_date` key, and a `description` key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_results(results):\n",
    "\n",
    "    results_list = []\n",
    "\n",
    "    for book in results['items']:\n",
    "\n",
    "        title = book['volumeInfo']['title']\n",
    "\n",
    "        # some books don't have authors, dates, or a description\n",
    "        try:\n",
    "            authors = ','.join(book['volumeInfo']['authors'])\n",
    "        except:\n",
    "            authors = 'NA'\n",
    "        \n",
    "        try:\n",
    "            published_date = book['volumeInfo']['publishedDate']\n",
    "        except:\n",
    "            published_date = 'NA'\n",
    "\n",
    "        try:\n",
    "            description = book['volumeInfo']['description']\n",
    "        except:\n",
    "            description = \"NA\"\n",
    "\n",
    "        results_dict = {'title': title,\n",
    "                        'authors': authors,\n",
    "                        'description': description,\n",
    "                        'published_date': published_date}\n",
    "        \n",
    "        results_list.append(results_dict)\n",
    "        \n",
    "    return(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = parse_results(results)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's explore the API using more parameters. You may have noticed that our query only gave us 10 books, but there are probably more than 10 books written about digital humanities. To adjust our search, we need to add in the `maxResults` parameter and the `startIndex` parameter. We can do that by adding these as keys to the `parameters` dictionary, and then run our request again. To read about these parameters, see the [documentation](https://developers.google.com/books/docs/v1/using#api_params)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'q': query,\n",
    "              'startIndex': 0,\n",
    "              'maxResults': 10}\n",
    "\n",
    "r = requests.get(books_url, params = parameters)\n",
    "\n",
    "print(r.url)\n",
    "\n",
    "results = r.json()\n",
    "\n",
    "print()\n",
    "\n",
    "parse_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can write a for loop to collect the first 100 results into `all_results`. But make sure you use `time.sleep` at the end of each loop! Python is so fast that if you write a for loop without pausing between calls you can overload someone's server, or get yourself (temporarily) banned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "parameters = {'q': query,\n",
    "          'maxResults': 20,\n",
    "          'startIndex': 0}\n",
    "\n",
    "all_results = []\n",
    "for i in range(5):\n",
    "    print(\"collecting page \" + str(i + 1))\n",
    "    \n",
    "    r = requests.get(books_url, params=parameters)\n",
    "    results = r.json()\n",
    "    parsed = parse_results(results)\n",
    "    all_results.extend(parsed)\n",
    "    \n",
    "    time.sleep(1) # very important to not overload API\n",
    "    parameters['startIndex'] += parameters['maxResults']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can write this data to a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "keys = all_results[0].keys()\n",
    "\n",
    "with open('books_search.csv', 'w') as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(all_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
